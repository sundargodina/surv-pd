def preprocess_features(df, categorical_cols, drop_cols=None):
    df = df.copy()
    
    # Drop non-informative or date columns
    if drop_cols is None:
        drop_cols = ['LOAN_ID', 'ORIG_DATE', 'FORECLOSURE_DATE', 'MATR_DT', 'date']
    df.drop(columns=[col for col in drop_cols if col in df.columns], inplace=True)
    
    # Identify categorical features to encode
    encode_cols = [col for col in categorical_cols if col in df.columns and col not in drop_cols]
    
    # One-hot encode
    df = pd.get_dummies(df, columns=encode_cols, drop_first=True)
    
    return df
df_clean = preprocess_features(data_df, categorical_cols)
feature_cols = [col for col in df_clean.columns if col not in ['survival_time', 'survival_event']]

import polars as pl

def check_high_correlations(pl_df: pl.DataFrame, threshold: float = 0.95):
    # Select numeric columns only
    numeric_types = {pl.Float32, pl.Float64, pl.Int32, pl.Int64, pl.UInt32, pl.UInt64}
    numeric_cols = [col for col, dtype in zip(pl_df.columns, pl_df.dtypes) if dtype in numeric_types]

    # Compute correlation matrix
    corr_df = pl_df.select(numeric_cols).corr()

    # Convert to Pandas for easier pair filtering
    corr_pd = corr_df.to_pandas()
    
    high_corr_pairs = []
    for i in range(len(corr_pd.columns)):
        for j in range(i + 1, len(corr_pd.columns)):
            corr_val = corr_pd.iloc[i, j]
            if abs(corr_val) > threshold:
                high_corr_pairs.append((
                    corr_pd.columns[i], 
                    corr_pd.columns[j], 
                    corr_val
                ))

    print(f"Highly correlated pairs (>|{threshold}|):")
    for i, j, val in sorted(high_corr_pairs, key=lambda x: -abs(x[2])):
        print(f"{i} ~ {j}: {val:.3f}")
    
    return high_corr_pairs
    
df_clean = pl.from_pandas(df_clean)
high_corr_pairs = check_high_correlations(df_clean, threshold=0.95)

columns_to_drop = [
    'OCLTV',
    'stage2_event',
    'stage2_survival_event',
    'survival_event',
    'time_to_default_raw',
    'ever_default_dlq',
    'money_credit_PC1',
    'markets_sentiment_PC1',
    'economic_activity_PC1'
]

df_clean = df_clean.drop(columns_to_drop)
